{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# CPSC5175 Lab 10 - Chapter 10\n#### Jamion Williams"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Problem 10.2\n##### Work upon the SystemAdministrators.csv dataset."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# necessities\n\nlibrary(caret)\nlibrary(plyr)\nset.seed(420)",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Import the dataset and interrogate it.\n\nraw.df <- read.csv(\"Datasets/SystemAdministrators.csv\",header = TRUE)\n\nstr(raw.df)\n\nhead(raw.df)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "'data.frame':\t75 obs. of  3 variables:\n $ Experience    : num  10.9 9.9 10.4 13.7 9.4 12.4 7.9 8.9 10.2 11.4 ...\n $ Training      : int  4 4 6 6 8 4 6 4 6 4 ...\n $ Completed.task: Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 2 ...\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  Experience Training Completed.task\n1 10.9       4        Yes           \n2  9.9       4        Yes           \n3 10.4       6        Yes           \n4 13.7       6        Yes           \n5  9.4       8        Yes           \n6 12.4       4        Yes           ",
            "text/latex": "A data.frame: 6 x 3\n\\begin{tabular}{r|lll}\n Experience & Training & Completed.task\\\\\n <dbl> & <int> & <fct>\\\\\n\\hline\n\t 10.9 & 4 & Yes\\\\\n\t  9.9 & 4 & Yes\\\\\n\t 10.4 & 6 & Yes\\\\\n\t 13.7 & 6 & Yes\\\\\n\t  9.4 & 8 & Yes\\\\\n\t 12.4 & 4 & Yes\\\\\n\\end{tabular}\n",
            "text/markdown": "\nA data.frame: 6 x 3\n\n| Experience &lt;dbl&gt; | Training &lt;int&gt; | Completed.task &lt;fct&gt; |\n|---|---|---|\n| 10.9 | 4 | Yes |\n|  9.9 | 4 | Yes |\n| 10.4 | 6 | Yes |\n| 13.7 | 6 | Yes |\n|  9.4 | 8 | Yes |\n| 12.4 | 4 | Yes |\n\n",
            "text/html": "<table>\n<caption>A data.frame: 6 x 3</caption>\n<thead>\n\t<tr><th scope=col>Experience</th><th scope=col>Training</th><th scope=col>Completed.task</th></tr>\n\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n</thead>\n<tbody>\n\t<tr><td>10.9</td><td>4</td><td>Yes</td></tr>\n\t<tr><td> 9.9</td><td>4</td><td>Yes</td></tr>\n\t<tr><td>10.4</td><td>6</td><td>Yes</td></tr>\n\t<tr><td>13.7</td><td>6</td><td>Yes</td></tr>\n\t<tr><td> 9.4</td><td>8</td><td>Yes</td></tr>\n\t<tr><td>12.4</td><td>4</td><td>Yes</td></tr>\n</tbody>\n</table>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Problem 10.2b\n##### Run a logistic regression using both predictors, using the entire dataset to train. What percentage is incorrectly classified as a \"No\"?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# backup the dataset and convert to categoricals\n\ntrain.df <- raw.df\n\ntrain.df$Experience <- factor(raw.df$Experience)\ntrain.df$Training   <- factor(raw.df$Training)\n\n#train.df$Completed.task <- mapvalues(train.df$Completed.task, \n#          from=c(\"Yes\",\"No\"), \n#          to=c(\"1\",\"0\"))\n\nstr(train.df)",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "'data.frame':\t75 obs. of  3 variables:\n $ Experience    : Factor w/ 56 levels \"2.7\",\"3.6\",\"3.8\",..: 51 48 50 56 47 55 41 45 49 52 ...\n $ Training      : Factor w/ 3 levels \"4\",\"6\",\"8\": 1 1 2 2 3 1 2 1 2 1 ...\n $ Completed.task: Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 2 2 2 2 2 2 ...\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# run the logit\n\nset.seed(420)\n\nlgrFit <- train(\n    Completed.task ~ .,\n    data=train.df,\n    method=\"glm\"\n)\n\nlgrFit",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message:\n“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message:\n“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message:\n“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message:\n“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message:\n“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message:\n“glm.fit: algorithm did not converge”Warning message:\n“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message:\n“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message:\n“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message:\n“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message:\n“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message:\n“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message:\n“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n“prediction from a rank-deficient fit may be misleading”Warning message:\n“glm.fit: fitted probabilities numerically 0 or 1 occurred”",
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generalized Linear Model \n\n75 samples\n 2 predictor\n 2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Bootstrapped (25 reps) \nSummary of sample sizes: 75, 75, 75, 75, 75, 75, ... \nResampling results:\n\n  Accuracy   Kappa      \n  0.5832897  -0.03167799\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "set.seed(420)\n\nsummary(lgrFit)\n\nconfusionMatrix(predict(lgrFit, train.df), train.df$Completed.task, positive=\"Yes\")",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\nCall:\nNULL\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-1.17741  -0.00002  -0.00002  -0.00002   1.17741  \n\nCoefficients:\n                 Estimate Std. Error z value Pr(>|z|)\n(Intercept)    -2.257e+01  4.820e+04   0.000    1.000\nExperience3.6  -7.249e-07  6.816e+04   0.000    1.000\nExperience3.8  -7.249e-07  6.816e+04   0.000    1.000\nExperience4    -7.249e-07  6.816e+04   0.000    1.000\nExperience4.1  -7.249e-07  6.816e+04   0.000    1.000\nExperience4.2  -7.249e-07  6.816e+04   0.000    1.000\nExperience4.3  -7.249e-07  6.816e+04   0.000    1.000\nExperience4.4  -7.248e-07  6.816e+04   0.000    1.000\nExperience4.5   1.109e+00  8.795e+04   0.000    1.000\nExperience4.6  -7.249e-07  6.816e+04   0.000    1.000\nExperience4.7  -7.249e-07  5.903e+04   0.000    1.000\nExperience4.8  -7.250e-07  6.816e+04   0.000    1.000\nExperience4.9  -7.249e-07  5.903e+04   0.000    1.000\nExperience5    -7.248e-07  5.903e+04   0.000    1.000\nExperience5.1  -7.249e-07  6.816e+04   0.000    1.000\nExperience5.2  -7.249e-07  5.565e+04   0.000    1.000\nExperience5.3  -7.249e-07  6.816e+04   0.000    1.000\nExperience5.4  -7.249e-07  5.903e+04   0.000    1.000\nExperience5.5   4.177e+01  6.596e+04   0.001    0.999\nExperience5.6  -7.248e-07  6.816e+04   0.000    1.000\nExperience5.7  -7.249e-07  6.816e+04   0.000    1.000\nExperience5.8  -7.249e-07  5.903e+04   0.000    1.000\nExperience5.9   1.109e+00  5.558e+04   0.000    1.000\nExperience6.1  -7.249e-07  5.903e+04   0.000    1.000\nExperience6.2   4.177e+01  7.425e+04   0.001    1.000\nExperience6.3  -7.250e-07  5.903e+04   0.000    1.000\nExperience6.4   4.177e+01  7.425e+04   0.001    1.000\nExperience6.5  -7.249e-07  5.903e+04   0.000    1.000\nExperience6.6   1.109e+00  5.558e+04   0.000    1.000\nExperience6.7  -7.249e-07  6.816e+04   0.000    1.000\nExperience6.8  -7.249e-07  6.816e+04   0.000    1.000\nExperience6.9  -7.249e-07  6.816e+04   0.000    1.000\nExperience7     2.257e+01  4.820e+04   0.000    1.000\nExperience7.1   4.177e+01  7.425e+04   0.001    1.000\nExperience7.2  -7.250e-07  6.816e+04   0.000    1.000\nExperience7.3   4.177e+01  7.425e+04   0.001    1.000\nExperience7.4   1.109e+00  8.795e+04   0.000    1.000\nExperience7.6   2.257e+01  4.820e+04   0.000    1.000\nExperience7.7  -7.249e-07  6.816e+04   0.000    1.000\nExperience7.8  -7.249e-07  6.816e+04   0.000    1.000\nExperience7.9   8.691e+01  7.425e+04   0.001    0.999\nExperience8    -7.249e-07  6.816e+04   0.000    1.000\nExperience8.2  -7.250e-07  6.816e+04   0.000    1.000\nExperience8.6   4.345e+01  5.250e+04   0.001    0.999\nExperience8.9   2.257e+01  4.820e+04   0.000    1.000\nExperience9.2   2.257e+01  4.820e+04   0.000    1.000\nExperience9.4   4.624e+01  8.795e+04   0.001    1.000\nExperience9.9   4.513e+01  6.816e+04   0.001    0.999\nExperience10.2  8.691e+01  7.425e+04   0.001    0.999\nExperience10.4  8.691e+01  7.425e+04   0.001    0.999\nExperience10.9  4.513e+01  6.816e+04   0.001    0.999\nExperience11.4  4.513e+01  6.816e+04   0.001    0.999\nExperience11.7  4.624e+01  8.795e+04   0.001    1.000\nExperience12.2 -7.249e-07  6.816e+04   0.000    1.000\nExperience12.4  4.513e+01  6.816e+04   0.001    0.999\nExperience13.7  8.691e+01  7.425e+04   0.001    0.999\nTraining6      -4.177e+01  2.944e+04  -0.001    0.999\nTraining8      -1.109e+00  5.558e+04   0.000    1.000\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 75.06  on 74  degrees of freedom\nResidual deviance: 11.09  on 17  degrees of freedom\nAIC: 127.09\n\nNumber of Fisher Scoring iterations: 21\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Confusion Matrix and Statistics\n\n          Reference\nPrediction No Yes\n       No  58   2\n       Yes  2  13\n                                         \n               Accuracy : 0.9467         \n                 95% CI : (0.869, 0.9853)\n    No Information Rate : 0.8            \n    P-Value [Acc > NIR] : 0.0003233      \n                                         \n                  Kappa : 0.8333         \n                                         \n Mcnemar's Test P-Value : 1.0000000      \n                                         \n            Sensitivity : 0.8667         \n            Specificity : 0.9667         \n         Pos Pred Value : 0.8667         \n         Neg Pred Value : 0.9667         \n             Prevalence : 0.2000         \n         Detection Rate : 0.1733         \n   Detection Prevalence : 0.2000         \n      Balanced Accuracy : 0.9167         \n                                         \n       'Positive' Class : Yes            \n                                         "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Problem 10.2c\n##### To decrease the percentage in part b, should the cutoff probability be increased or decreased?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "Well, according to this (which I doubt, partially because of the warnings), I was only \"wrong\" 2 times, so I don't think I would do either, especially at 94% performance!"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "r",
      "display_name": "R",
      "language": "R"
    },
    "language_info": {
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.5.3",
      "file_extension": ".r",
      "codemirror_mode": "r"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}